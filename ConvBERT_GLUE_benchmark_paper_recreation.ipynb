{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4c49088048345d69287a2406b3c25be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79d7a6504eef4129917bca32900c2d6d",
              "IPY_MODEL_f69d9f6815704a73b0b3f737a31b8efa",
              "IPY_MODEL_bb76e8dd8e624b2aa3301bb5251fc895"
            ],
            "layout": "IPY_MODEL_5bb5da5a71b34b28835bdc67d1920eef"
          }
        },
        "79d7a6504eef4129917bca32900c2d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19d5560e2bc24e2c94d0d47fae127a99",
            "placeholder": "​",
            "style": "IPY_MODEL_7a7b4d057a3141359260d6b1a513c8d9",
            "value": "vocab.txt: 100%"
          }
        },
        "f69d9f6815704a73b0b3f737a31b8efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bbbdb322682490db94225044037ab39",
            "max": 266699,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d9c6228306c4a58a66028142700f910",
            "value": 266699
          }
        },
        "bb76e8dd8e624b2aa3301bb5251fc895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e52c3e5a2854e9294223c648db4c368",
            "placeholder": "​",
            "style": "IPY_MODEL_7856c2e6e0174b5180121f77d2fbd5c4",
            "value": " 267k/267k [00:00&lt;00:00, 5.87MB/s]"
          }
        },
        "5bb5da5a71b34b28835bdc67d1920eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d5560e2bc24e2c94d0d47fae127a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a7b4d057a3141359260d6b1a513c8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bbbdb322682490db94225044037ab39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9c6228306c4a58a66028142700f910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e52c3e5a2854e9294223c648db4c368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7856c2e6e0174b5180121f77d2fbd5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "904a021bb4a34fc5b447fcf3caedcbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d246d03c7c2c48199730ce5e2057ad45",
              "IPY_MODEL_00b186e3bca14b378c2846988198c4c8",
              "IPY_MODEL_06481826277a4e63b7e21163e8049920"
            ],
            "layout": "IPY_MODEL_ff5b740324814178857be9538e7a0ed1"
          }
        },
        "d246d03c7c2c48199730ce5e2057ad45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3891329fb6e344d598e41f9a62f038c9",
            "placeholder": "​",
            "style": "IPY_MODEL_c3304afb280d4d48800d800768c0213e",
            "value": "config.json: 100%"
          }
        },
        "00b186e3bca14b378c2846988198c4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dde30297fd2405e8c1eb8ccabd5593c",
            "max": 674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9de7a2f9aa944c6a53d0d86fd680d1e",
            "value": 674
          }
        },
        "06481826277a4e63b7e21163e8049920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb6b8a2b56df4c38b1e41d75b7c984c8",
            "placeholder": "​",
            "style": "IPY_MODEL_61de59b6cc194a52819df835686d221c",
            "value": " 674/674 [00:00&lt;00:00, 55.3kB/s]"
          }
        },
        "ff5b740324814178857be9538e7a0ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3891329fb6e344d598e41f9a62f038c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3304afb280d4d48800d800768c0213e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dde30297fd2405e8c1eb8ccabd5593c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9de7a2f9aa944c6a53d0d86fd680d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb6b8a2b56df4c38b1e41d75b7c984c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61de59b6cc194a52819df835686d221c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **ConvBERT Reproduction Study: Fine-tuning for Performance on GLUE Benchmark**\n",
        "\n",
        "This notebook focuses on the reproduction of the ConvBERT model's performance on the GLUE benchmark, a collection of natural language understanding tasks. By fine-tuning ConvBERT across multiple tasks such as sentiment analysis, paraphrase detection, and textual entailment, the study aims to validate the original paper's findings. The notebook provides an in-depth implementation of fine-tuning using the PyTorch framework and Hugging Face's Transformers library, with optimization techniques like gradient accumulation and mixed precision training to handle computational challenges."
      ],
      "metadata": {
        "id": "CuDXB20GXCwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofhk9G-SQEla",
        "outputId": "2f210485-d2d4-43c6-b5c5-b504e9705c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-3.0.1 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch transformers datasets evaluate\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import ConvBertTokenizer, ConvBertForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import os\n",
        "from torch.optim.adamw import AdamW\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "from torch.cuda.amp import autocast, GradScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GLUE tasks and their respective number of labels for classification or regression\n",
        "# Each key represents a GLUE task, and the corresponding value is the number of labels for that task.\n",
        "# For example:\n",
        "# - SST-2 (Sentiment Analysis) and CoLA (Linguistic Acceptability) are binary classification tasks (2 labels).\n",
        "# - MRPC (Paraphrase Detection), QQP (Question Paraphrase), QNLI, RTE, and WNLI are also binary classification tasks (2 labels).\n",
        "# - STS-B (Semantic Textual Similarity) is a regression task (1 label) where the goal is to predict a continuous score.\n",
        "# - MNLI (Multi-Genre Natural Language Inference) is a multi-class classification task with 3 labels (entailment, neutral, contradiction).\n",
        "\n",
        "glue_tasks = {\n",
        "    \"sst2\": 2,  # SST-2: Sentiment analysis (binary classification)\n",
        "    \"cola\": 2,  # CoLA: Linguistic acceptability (binary classification)\n",
        "    \"mrpc\": 2,  # MRPC: Paraphrase detection (binary classification)\n",
        "    \"stsb\": 1,  # STS-B: Semantic similarity (regression task, 1 continuous value)\n",
        "    \"qqp\": 2,   # QQP: Question paraphrase detection (binary classification)\n",
        "    \"mnli\": 3,  # MNLI: Multi-genre NLI (3-class classification: entailment, neutral, contradiction)\n",
        "    \"qnli\": 2,  # QNLI: Question-answering NLI (binary classification)\n",
        "    \"rte\": 2,   # RTE: Recognizing textual entailment (binary classification)\n",
        "    \"wnli\": 2   # WNLI: Winograd NLI (binary classification, known for its difficulty)\n",
        "}\n"
      ],
      "metadata": {
        "id": "8d7UngcNqFpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ConvBERT tokenizer and model for sequence classification\n",
        "model_name = \"YituTech/conv-bert-base\"\n",
        "tokenizer = ConvBertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "e4c49088048345d69287a2406b3c25be",
            "79d7a6504eef4129917bca32900c2d6d",
            "f69d9f6815704a73b0b3f737a31b8efa",
            "bb76e8dd8e624b2aa3301bb5251fc895",
            "5bb5da5a71b34b28835bdc67d1920eef",
            "19d5560e2bc24e2c94d0d47fae127a99",
            "7a7b4d057a3141359260d6b1a513c8d9",
            "0bbbdb322682490db94225044037ab39",
            "0d9c6228306c4a58a66028142700f910",
            "2e52c3e5a2854e9294223c648db4c368",
            "7856c2e6e0174b5180121f77d2fbd5c4",
            "904a021bb4a34fc5b447fcf3caedcbe7",
            "d246d03c7c2c48199730ce5e2057ad45",
            "00b186e3bca14b378c2846988198c4c8",
            "06481826277a4e63b7e21163e8049920",
            "ff5b740324814178857be9538e7a0ed1",
            "3891329fb6e344d598e41f9a62f038c9",
            "c3304afb280d4d48800d800768c0213e",
            "1dde30297fd2405e8c1eb8ccabd5593c",
            "c9de7a2f9aa944c6a53d0d86fd680d1e",
            "fb6b8a2b56df4c38b1e41d75b7c984c8",
            "61de59b6cc194a52819df835686d221c"
          ]
        },
        "id": "eJn_187_QiL9",
        "outputId": "66f1b81e-13d9-4c62-ec9d-ae278b151e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/267k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4c49088048345d69287a2406b3c25be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/674 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "904a021bb4a34fc5b447fcf3caedcbe7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom collate function to handle padding of sequences within a batch\n",
        "# This function is useful for making sure that sequences in a batch have the same length\n",
        "# by padding them appropriately. This is necessary when dealing with variable-length sequences (e.g., sentences).\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Extract 'input_ids', 'attention_mask', and 'label' from each item in the batch\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    labels = [item['label'] for item in batch]\n",
        "\n",
        "    # Pad the input_ids and attention_mask to the same length for all samples in the batch\n",
        "    # pad_sequence pads sequences with zeros by default to make them of equal length.\n",
        "    # 'batch_first=True' ensures that the output tensor has the batch size as the first dimension.\n",
        "    input_ids_padded = pad_sequence(input_ids, batch_first=True)\n",
        "    attention_mask_padded = pad_sequence(attention_mask, batch_first=True)\n",
        "\n",
        "    # Convert the labels to a tensor since they are plain Python lists\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    # Return a dictionary with the padded input_ids, attention_mask, and labels\n",
        "    return {\n",
        "        'input_ids': input_ids_padded,            # Padded input token IDs\n",
        "        'attention_mask': attention_mask_padded,  # Padded attention mask\n",
        "        'label': labels                           # Labels for the batch\n",
        "    }\n"
      ],
      "metadata": {
        "id": "89fsoiyoqgv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive to save model checkpoints\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojI93LKfaXUW",
        "outputId": "42583dcf-519b-4798-f404-4ab9c52de18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Initialize gradient scaler for mixed precision training\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Gradient accumulation setup\n",
        "accumulation_steps = 8  # Adjust this based on your memory requirements\n",
        "\n",
        "# Directory to save checkpoints\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "def save_checkpoint(model, optimizer, task):\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"{task}_final.pth\")\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f\"\\nCheckpoint saved for {task}: {checkpoint_path}\\n\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, task):\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"{task}_final.pth\")\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(f\"\\nCheckpoint loaded for {task}: {checkpoint_path}\\n\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"\\nNo checkpoint found for {task}. Starting fresh.\\n\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Initialize dictionary to store task accuracies/metrics\n",
        "task_metrics = {}\n",
        "\n",
        "# Fine-tune for each GLUE task\n",
        "for task, num_labels in glue_tasks.items():\n",
        "    print(f\"\\n\\nFine-tuning for task: {task}\")\n",
        "\n",
        "    # Load dataset for the current task\n",
        "    dataset = load_dataset(\"glue\", task)\n",
        "\n",
        "    if task == 'mnli':  # MNLI has 'validation_matched' and 'validation_mismatched'\n",
        "        train_dataset = dataset['train']\n",
        "        validation_matched_dataset = dataset['validation_matched']\n",
        "        validation_mismatched_dataset = dataset['validation_mismatched']\n",
        "    else:\n",
        "        train_dataset = dataset['train']\n",
        "        test_dataset = dataset['validation']  # For tasks other than MNLI\n",
        "\n",
        "    # Tokenize the data\n",
        "    def tokenize(batch):\n",
        "        if task in ['stsb', 'mrpc', 'qqp', 'mnli', 'rte', 'wnli']:  # Tasks with two sentences\n",
        "            if 'premise' in batch and 'hypothesis' in batch:\n",
        "                return tokenizer(batch['premise'], batch['hypothesis'], padding=True, truncation=True, max_length=512)\n",
        "            elif 'sentence1' in batch:\n",
        "                return tokenizer(batch['sentence1'], batch['sentence2'], padding=True, truncation=True, max_length=512)\n",
        "            elif 'question1' in batch:  # For QQP task\n",
        "                return tokenizer(batch['question1'], batch['question2'], padding=True, truncation=True, max_length=512)\n",
        "        else:  # Tasks with one sentence\n",
        "            return tokenizer(batch['sentence'], padding=True, truncation=True, max_length=512)\n",
        "\n",
        "\n",
        "    # Apply tokenization\n",
        "    train_dataset = train_dataset.map(lambda x: tokenize(x), batched=True)\n",
        "\n",
        "    if task == 'mnli':\n",
        "        validation_matched_dataset = validation_matched_dataset.map(lambda x: tokenize(x), batched=True)\n",
        "        validation_mismatched_dataset = validation_mismatched_dataset.map(lambda x: tokenize(x), batched=True)\n",
        "    else:\n",
        "        test_dataset = test_dataset.map(lambda x: tokenize(x), batched=True)\n",
        "\n",
        "    # Convert dataset to PyTorch tensors\n",
        "    train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    if task == 'mnli':\n",
        "        validation_matched_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "        validation_mismatched_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "    else:\n",
        "        test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    # Load the ConvBERT model for classification\n",
        "    model = ConvBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "    # Set up the optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "\n",
        "    # Load the checkpoint if it exists\n",
        "    checkpoint_loaded = load_checkpoint(model, optimizer, task)\n",
        "\n",
        "    # Prepare DataLoader with optimized settings\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "\n",
        "    if task == 'mnli':\n",
        "        validation_matched_dataloader = DataLoader(validation_matched_dataset, batch_size=16, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "        validation_mismatched_dataloader = DataLoader(validation_mismatched_dataset, batch_size=16, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "    else:\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # Move model to the appropriate device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    if not checkpoint_loaded:  # Skip training if checkpoint is loaded\n",
        "        # Fine-tuning loop with gradient accumulation and mixed precision\n",
        "        model.train()\n",
        "        for epoch in range(3):  # Use 3 epochs for each task\n",
        "            total_loss = 0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            for i, batch in enumerate(train_dataloader):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "\n",
        "                # Autocast for mixed precision training\n",
        "                with autocast():\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss / accumulation_steps  # Scale the loss for accumulation\n",
        "\n",
        "                # Backpropagation\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                # Update weights after accumulation steps\n",
        "                if (i + 1) % accumulation_steps == 0:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                total_loss += loss.item() * accumulation_steps  # Re-scale the loss back\n",
        "\n",
        "            avg_loss = total_loss / len(train_dataloader)\n",
        "            print(f\"Epoch {epoch+1}, Task: {task}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Save checkpoint after completing the task\n",
        "        save_checkpoint(model, optimizer, task)\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "\n",
        "    if task == 'mnli':\n",
        "        # Evaluate on both validation_matched and validation_mismatched datasets\n",
        "        def evaluate_mnli(split_name, dataloader):\n",
        "            predictions, true_labels = [], []\n",
        "            with torch.no_grad():\n",
        "                for batch in dataloader:\n",
        "                    input_ids = batch['input_ids'].to(device)\n",
        "                    attention_mask = batch['attention_mask'].to(device)\n",
        "                    labels = batch['label'].to(device)\n",
        "\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "                    predictions.extend(preds.cpu().numpy())\n",
        "                    true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = accuracy_score(true_labels, predictions)\n",
        "            print(f\"\\nTask: {task} ({split_name}), Test Accuracy: {accuracy:.4f}\")\n",
        "            # Store the accuracy for GLUE score calculation\n",
        "            task_metrics[f\"{task}_{split_name}\"] = accuracy  # Save for both matched and mismatched\n",
        "\n",
        "        # Evaluate on both splits\n",
        "        evaluate_mnli('validation_matched', validation_matched_dataloader)\n",
        "        evaluate_mnli('validation_mismatched', validation_mismatched_dataloader)\n",
        "\n",
        "    else:\n",
        "        predictions, true_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_dataloader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "\n",
        "                # Regression task (STS-B)\n",
        "                if task == 'stsb':\n",
        "                    preds = logits.squeeze()  # No need for argmax in regression\n",
        "                else:  # Classification tasks\n",
        "                    preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "                predictions.extend(preds.cpu().numpy())\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        if task == 'stsb':  # Pearson correlation for regression task\n",
        "            pearson_corr = pearsonr(true_labels, predictions)[0]\n",
        "            mse = mean_squared_error(true_labels, predictions)\n",
        "            print(f\"\\nTask: {task}, Pearson Correlation: {pearson_corr:.4f}, MSE: {mse:.4f}\")\n",
        "            task_metrics[task] = pearson_corr  # Store Pearson correlation for GLUE score\n",
        "        else:  # Accuracy for classification tasks\n",
        "            accuracy = accuracy_score(true_labels, predictions)\n",
        "            print(f\"\\nTask: {task}, Test Accuracy: {accuracy:.4f}\")\n",
        "            task_metrics[task] = accuracy  # Store accuracy for GLUE score\n",
        "\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RyyHFppR7rw",
        "outputId": "e3e76014-af30-4c8a-8195-6c3e59268d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Fine-tuning for task: sst2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for sst2: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/sst2_final.pth\n",
            "\n",
            "\n",
            "Task: sst2, Test Accuracy: 0.9266\n",
            "\n",
            "\n",
            "Fine-tuning for task: cola\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for cola: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/cola_final.pth\n",
            "\n",
            "\n",
            "Task: cola, Test Accuracy: 0.8543\n",
            "\n",
            "\n",
            "Fine-tuning for task: mrpc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for mrpc: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/mrpc_final.pth\n",
            "\n",
            "\n",
            "Task: mrpc, Test Accuracy: 0.8750\n",
            "\n",
            "\n",
            "Fine-tuning for task: stsb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for stsb: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/stsb_final.pth\n",
            "\n",
            "\n",
            "Task: stsb, Pearson Correlation: 0.9028, MSE: 0.4367\n",
            "\n",
            "\n",
            "Fine-tuning for task: qqp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for qqp: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/qqp_final.pth\n",
            "\n",
            "\n",
            "Task: qqp, Test Accuracy: 0.9146\n",
            "\n",
            "\n",
            "Fine-tuning for task: mnli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for mnli: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/mnli_final.pth\n",
            "\n",
            "\n",
            "Task: mnli (validation_matched), Test Accuracy: 0.8639\n",
            "\n",
            "Task: mnli (validation_mismatched), Test Accuracy: 0.8648\n",
            "\n",
            "\n",
            "Fine-tuning for task: qnli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for qnli: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/qnli_final.pth\n",
            "\n",
            "\n",
            "Task: qnli, Test Accuracy: 0.6110\n",
            "\n",
            "\n",
            "Fine-tuning for task: rte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for rte: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/rte_final.pth\n",
            "\n",
            "\n",
            "Task: rte, Test Accuracy: 0.7112\n",
            "\n",
            "\n",
            "Fine-tuning for task: wnli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checkpoint loaded for wnli: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/wnli_final.pth\n",
            "\n",
            "\n",
            "Task: wnli, Test Accuracy: 0.5634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all the accuracies and calculate the GLUE score\n",
        "print(\"\\nTask Metrics Summary:\")\n",
        "for task, score in task_metrics.items():\n",
        "    print(f\"{task}: {score:.4f}\")\n",
        "\n",
        "# Calculate GLUE score as the average of all metrics\n",
        "glue_score = sum(task_metrics.values()) / len(task_metrics)\n",
        "print(f\"\\nGLUE Score: {glue_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ-Aj9BzF1iQ",
        "outputId": "3e948f00-7592-42d8-d071-e00d979d0b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task Metrics Summary:\n",
            "sst2: 0.9266\n",
            "cola: 0.8543\n",
            "mrpc: 0.8750\n",
            "stsb: 0.9028\n",
            "qqp: 0.9146\n",
            "mnli_validation_matched: 0.8639\n",
            "mnli_validation_mismatched: 0.8648\n",
            "qnli: 0.6110\n",
            "rte: 0.7112\n",
            "wnli: 0.5634\n",
            "\n",
            "GLUE Score: 0.8088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6DiVjCP5UXDJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}