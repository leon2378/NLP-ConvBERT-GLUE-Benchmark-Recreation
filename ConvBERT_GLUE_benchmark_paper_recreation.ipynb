{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuDXB20GXCwA"
      },
      "source": [
        "## **ConvBERT Reproduction Study: Fine-tuning for Performance on GLUE Benchmark**\n",
        "\n",
        "This notebook focuses on the reproduction of the ConvBERT model's performance on the GLUE benchmark, a collection of natural language understanding tasks. By fine-tuning ConvBERT across multiple tasks such as sentiment analysis, paraphrase detection, and textual entailment, the study aims to validate the original paper's findings. The notebook provides an in-depth implementation of fine-tuning using the PyTorch framework and Hugging Face's Transformers library, with optimization techniques like gradient accumulation and mixed precision training to handle computational challenges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofhk9G-SQEla",
        "outputId": "2f210485-d2d4-43c6-b5c5-b504e9705c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (2.4.1)\n",
            "Requirement already satisfied: transformers in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (4.45.1)\n",
            "Requirement already satisfied: datasets in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (2.19.2)\n",
            "Requirement already satisfied: evaluate in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (0.4.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (0.20.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from datasets) (3.10.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: colorama in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\leon-pc\\anaconda3\\envs\\torch_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install torch transformers datasets evaluate\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import ConvBertTokenizer, ConvBertForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import os\n",
        "from torch.optim.adamw import AdamW\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "#from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.amp.grad_scaler import GradScaler\n",
        "from torch.amp.autocast_mode import autocast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8d7UngcNqFpq"
      },
      "outputs": [],
      "source": [
        "# Define the GLUE tasks and their respective number of labels for classification or regression\n",
        "# Each key represents a GLUE task, and the corresponding value is the number of labels for that task.\n",
        "# For example:\n",
        "# - SST-2 (Sentiment Analysis) and CoLA (Linguistic Acceptability) are binary classification tasks (2 labels).\n",
        "# - MRPC (Paraphrase Detection), QQP (Question Paraphrase), QNLI, RTE, and WNLI are also binary classification tasks (2 labels).\n",
        "# - STS-B (Semantic Textual Similarity) is a regression task (1 label) where the goal is to predict a continuous score.\n",
        "# - MNLI (Multi-Genre Natural Language Inference) is a multi-class classification task with 3 labels (entailment, neutral, contradiction).\n",
        "\n",
        "glue_tasks = {\n",
        "    \"sst2\": 2,  # SST-2: Sentiment analysis (binary classification)\n",
        "    \"cola\": 2,  # CoLA: Linguistic acceptability (binary classification)\n",
        "    \"mrpc\": 2,  # MRPC: Paraphrase detection (binary classification)\n",
        "    \"stsb\": 1,  # STS-B: Semantic similarity (regression task, 1 continuous value)\n",
        "    \"qqp\": 2,   # QQP: Question paraphrase detection (binary classification)\n",
        "    \"mnli\": 3,  # MNLI: Multi-genre NLI (3-class classification: entailment, neutral, contradiction)\n",
        "    \"qnli\": 2,  # QNLI: Question-answering NLI (binary classification)\n",
        "    \"rte\": 2,   # RTE: Recognizing textual entailment (binary classification)\n",
        "    \"wnli\": 2   # WNLI: Winograd NLI (binary classification, known for its difficulty)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "e4c49088048345d69287a2406b3c25be",
            "79d7a6504eef4129917bca32900c2d6d",
            "f69d9f6815704a73b0b3f737a31b8efa",
            "bb76e8dd8e624b2aa3301bb5251fc895",
            "5bb5da5a71b34b28835bdc67d1920eef",
            "19d5560e2bc24e2c94d0d47fae127a99",
            "7a7b4d057a3141359260d6b1a513c8d9",
            "0bbbdb322682490db94225044037ab39",
            "0d9c6228306c4a58a66028142700f910",
            "2e52c3e5a2854e9294223c648db4c368",
            "7856c2e6e0174b5180121f77d2fbd5c4",
            "904a021bb4a34fc5b447fcf3caedcbe7",
            "d246d03c7c2c48199730ce5e2057ad45",
            "00b186e3bca14b378c2846988198c4c8",
            "06481826277a4e63b7e21163e8049920",
            "ff5b740324814178857be9538e7a0ed1",
            "3891329fb6e344d598e41f9a62f038c9",
            "c3304afb280d4d48800d800768c0213e",
            "1dde30297fd2405e8c1eb8ccabd5593c",
            "c9de7a2f9aa944c6a53d0d86fd680d1e",
            "fb6b8a2b56df4c38b1e41d75b7c984c8",
            "61de59b6cc194a52819df835686d221c"
          ]
        },
        "id": "eJn_187_QiL9",
        "outputId": "66f1b81e-13d9-4c62-ec9d-ae278b151e56"
      },
      "outputs": [],
      "source": [
        "# Load ConvBERT tokenizer and model for sequence classification\n",
        "model_name = \"YituTech/conv-bert-base\"\n",
        "tokenizer = ConvBertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89fsoiyoqgv0"
      },
      "outputs": [],
      "source": [
        "# Define a custom collate function to handle padding of sequences within a batch\n",
        "# This function is useful for making sure that sequences in a batch have the same length\n",
        "# by padding them appropriately. This is necessary when dealing with variable-length sequences (e.g., sentences).\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Extract 'input_ids', 'attention_mask', and 'label' from each item in the batch\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    labels = [item['label'] for item in batch]\n",
        "\n",
        "    # Pad the input_ids and attention_mask to the same length for all samples in the batch\n",
        "    # pad_sequence pads sequences with zeros by default to make them of equal length.\n",
        "    # 'batch_first=True' ensures that the output tensor has the batch size as the first dimension.\n",
        "    input_ids_padded = pad_sequence(input_ids, batch_first=True)\n",
        "    attention_mask_padded = pad_sequence(attention_mask, batch_first=True)\n",
        "\n",
        "    # Convert the labels to a tensor since they are plain Python lists\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    # Return a dictionary with the padded input_ids, attention_mask, and labels\n",
        "    return {\n",
        "        'input_ids': input_ids_padded,            # Padded input token IDs\n",
        "        'attention_mask': attention_mask_padded,  # Padded attention mask\n",
        "        'label': labels                           # Labels for the batch\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RyyHFppR7rw",
        "outputId": "e3e76014-af30-4c8a-8195-6c3e59268d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Fine-tuning for task: sst2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for sst2: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/sst2_final.pth\n",
            "\n",
            "\n",
            "Task: sst2, Test Accuracy: 0.9266\n",
            "\n",
            "\n",
            "Fine-tuning for task: cola\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for cola: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/cola_final.pth\n",
            "\n",
            "\n",
            "Task: cola, Test Accuracy: 0.8543\n",
            "\n",
            "\n",
            "Fine-tuning for task: mrpc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for mrpc: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/mrpc_final.pth\n",
            "\n",
            "\n",
            "Task: mrpc, Test Accuracy: 0.8750\n",
            "\n",
            "\n",
            "Fine-tuning for task: stsb\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for stsb: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/stsb_final.pth\n",
            "\n",
            "\n",
            "Task: stsb, Pearson Correlation: 0.9028, MSE: 0.4367\n",
            "\n",
            "\n",
            "Fine-tuning for task: qqp\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for qqp: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/qqp_final.pth\n",
            "\n",
            "\n",
            "Task: qqp, Test Accuracy: 0.9146\n",
            "\n",
            "\n",
            "Fine-tuning for task: mnli\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for mnli: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/mnli_final.pth\n",
            "\n",
            "\n",
            "Task: mnli (validation_matched), Test Accuracy: 0.8639\n",
            "\n",
            "Task: mnli (validation_mismatched), Test Accuracy: 0.8648\n",
            "\n",
            "\n",
            "Fine-tuning for task: qnli\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for qnli: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/qnli_final.pth\n",
            "\n",
            "\n",
            "Task: qnli, Test Accuracy: 0.6110\n",
            "\n",
            "\n",
            "Fine-tuning for task: rte\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for rte: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/rte_final.pth\n",
            "\n",
            "\n",
            "Task: rte, Test Accuracy: 0.7112\n",
            "\n",
            "\n",
            "Fine-tuning for task: wnli\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint loaded for wnli: /content/drive/MyDrive/Advanced NLP/Ass_2/model_checkpoints/wnli_final.pth\n",
            "\n",
            "\n",
            "Task: wnli, Test Accuracy: 0.5634\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Initialize gradient scaler for mixed precision training\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Gradient accumulation setup\n",
        "accumulation_steps = 8  # Adjust this based on your memory requirements\n",
        "\n",
        "# Directory to save checkpoints\n",
        "checkpoint_dir = \"model_checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "def save_checkpoint(model, optimizer, task):\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"{task}_final.pth\")\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f\"\\nCheckpoint saved for {task}: {checkpoint_path}\\n\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, task):\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"{task}_final.pth\")\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(f\"\\nCheckpoint loaded for {task}: {checkpoint_path}\\n\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"\\nNo checkpoint found for {task}. Starting fresh.\\n\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Initialize dictionary to store task accuracies/metrics\n",
        "task_metrics = {}\n",
        "\n",
        "# Fine-tune for each GLUE task\n",
        "for task, num_labels in glue_tasks.items():\n",
        "    print(f\"\\n\\nFine-tuning for task: {task}\")\n",
        "\n",
        "    # Load dataset for the current task\n",
        "    dataset = load_dataset(\"glue\", task)\n",
        "\n",
        "    if task == 'mnli':  # MNLI has 'validation_matched' and 'validation_mismatched'\n",
        "        train_dataset = dataset['train']\n",
        "        validation_matched_dataset = dataset['validation_matched']\n",
        "        validation_mismatched_dataset = dataset['validation_mismatched']\n",
        "    else:\n",
        "        train_dataset = dataset['train']\n",
        "        test_dataset = dataset['validation']  # For tasks other than MNLI\n",
        "\n",
        "    # Tokenize the data\n",
        "    def tokenize(batch):\n",
        "        if task in ['stsb', 'mrpc', 'qqp', 'mnli', 'rte', 'wnli']:  # Tasks with two sentences\n",
        "            if 'premise' in batch and 'hypothesis' in batch:\n",
        "                return tokenizer(batch['premise'], batch['hypothesis'], padding=True, truncation=True, max_length=512)\n",
        "            elif 'sentence1' in batch:\n",
        "                return tokenizer(batch['sentence1'], batch['sentence2'], padding=True, truncation=True, max_length=512)\n",
        "            elif 'question1' in batch:  # For QQP task\n",
        "                return tokenizer(batch['question1'], batch['question2'], padding=True, truncation=True, max_length=512)\n",
        "        else:  # Tasks with one sentence\n",
        "            return tokenizer(batch['sentence'], padding=True, truncation=True, max_length=512)\n",
        "\n",
        "\n",
        "    # Apply tokenization\n",
        "    train_dataset = train_dataset.map(lambda x: tokenize(x), batched=True)\n",
        "\n",
        "    if task == 'mnli':\n",
        "        validation_matched_dataset = validation_matched_dataset.map(lambda x: tokenize(x), batched=True)\n",
        "        validation_mismatched_dataset = validation_mismatched_dataset.map(lambda x: tokenize(x), batched=True)\n",
        "    else:\n",
        "        test_dataset = test_dataset.map(lambda x: tokenize(x), batched=True)\n",
        "\n",
        "    # Convert dataset to PyTorch tensors\n",
        "    train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    if task == 'mnli':\n",
        "        validation_matched_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "        validation_mismatched_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "    else:\n",
        "        test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    # Load the ConvBERT model for classification\n",
        "    model = ConvBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "    # Set up the optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "\n",
        "    # Load the checkpoint if it exists\n",
        "    checkpoint_loaded = load_checkpoint(model, optimizer, task)\n",
        "\n",
        "    # Prepare DataLoader with optimized settings\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "\n",
        "    if task == 'mnli':\n",
        "        validation_matched_dataloader = DataLoader(validation_matched_dataset, batch_size=16, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "        validation_mismatched_dataloader = DataLoader(validation_mismatched_dataset, batch_size=16, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "    else:\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # Move model to the appropriate device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    if not checkpoint_loaded:  # Skip training if checkpoint is loaded\n",
        "        # Fine-tuning loop with gradient accumulation and mixed precision\n",
        "        model.train()\n",
        "        for epoch in range(3):  # Use 3 epochs for each task\n",
        "            total_loss = 0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            for i, batch in enumerate(train_dataloader):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "\n",
        "                # Autocast for mixed precision training\n",
        "                with autocast():\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss / accumulation_steps  # Scale the loss for accumulation\n",
        "\n",
        "                # Backpropagation\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                # Update weights after accumulation steps\n",
        "                if (i + 1) % accumulation_steps == 0:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                total_loss += loss.item() * accumulation_steps  # Re-scale the loss back\n",
        "\n",
        "            avg_loss = total_loss / len(train_dataloader)\n",
        "            print(f\"Epoch {epoch+1}, Task: {task}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Save checkpoint after completing the task\n",
        "        save_checkpoint(model, optimizer, task)\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "\n",
        "    if task == 'mnli':\n",
        "        # Evaluate on both validation_matched and validation_mismatched datasets\n",
        "        def evaluate_mnli(split_name, dataloader):\n",
        "            predictions, true_labels = [], []\n",
        "            with torch.no_grad():\n",
        "                for batch in dataloader:\n",
        "                    input_ids = batch['input_ids'].to(device)\n",
        "                    attention_mask = batch['attention_mask'].to(device)\n",
        "                    labels = batch['label'].to(device)\n",
        "\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "                    predictions.extend(preds.cpu().numpy())\n",
        "                    true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = accuracy_score(true_labels, predictions)\n",
        "            print(f\"\\nTask: {task} ({split_name}), Test Accuracy: {accuracy:.4f}\")\n",
        "            # Store the accuracy for GLUE score calculation\n",
        "            task_metrics[f\"{task}_{split_name}\"] = accuracy  # Save for both matched and mismatched\n",
        "\n",
        "        # Evaluate on both splits\n",
        "        evaluate_mnli('validation_matched', validation_matched_dataloader)\n",
        "        evaluate_mnli('validation_mismatched', validation_mismatched_dataloader)\n",
        "\n",
        "    else:\n",
        "        predictions, true_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_dataloader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "\n",
        "                # Regression task (STS-B)\n",
        "                if task == 'stsb':\n",
        "                    preds = logits.squeeze()  # No need for argmax in regression\n",
        "                else:  # Classification tasks\n",
        "                    preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "                predictions.extend(preds.cpu().numpy())\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        if task == 'stsb':  # Pearson correlation for regression task\n",
        "            pearson_corr = pearsonr(true_labels, predictions)[0]\n",
        "            mse = mean_squared_error(true_labels, predictions)\n",
        "            print(f\"\\nTask: {task}, Pearson Correlation: {pearson_corr:.4f}, MSE: {mse:.4f}\")\n",
        "            task_metrics[task] = pearson_corr  # Store Pearson correlation for GLUE score\n",
        "        else:  # Accuracy for classification tasks\n",
        "            accuracy = accuracy_score(true_labels, predictions)\n",
        "            print(f\"\\nTask: {task}, Test Accuracy: {accuracy:.4f}\")\n",
        "            task_metrics[task] = accuracy  # Store accuracy for GLUE score\n",
        "\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ-Aj9BzF1iQ",
        "outputId": "3e948f00-7592-42d8-d071-e00d979d0b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Task Metrics Summary:\n",
            "sst2: 0.9266\n",
            "cola: 0.8543\n",
            "mrpc: 0.8750\n",
            "stsb: 0.9028\n",
            "qqp: 0.9146\n",
            "mnli_validation_matched: 0.8639\n",
            "mnli_validation_mismatched: 0.8648\n",
            "qnli: 0.6110\n",
            "rte: 0.7112\n",
            "wnli: 0.5634\n",
            "\n",
            "GLUE Score: 0.8088\n"
          ]
        }
      ],
      "source": [
        "# Print all the accuracies and calculate the GLUE score\n",
        "print(\"\\nTask Metrics Summary:\")\n",
        "for task, score in task_metrics.items():\n",
        "    print(f\"{task}: {score:.4f}\")\n",
        "\n",
        "# Calculate GLUE score as the average of all metrics\n",
        "glue_score = sum(task_metrics.values()) / len(task_metrics)\n",
        "print(f\"\\nGLUE Score: {glue_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DiVjCP5UXDJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00b186e3bca14b378c2846988198c4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dde30297fd2405e8c1eb8ccabd5593c",
            "max": 674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9de7a2f9aa944c6a53d0d86fd680d1e",
            "value": 674
          }
        },
        "06481826277a4e63b7e21163e8049920": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb6b8a2b56df4c38b1e41d75b7c984c8",
            "placeholder": "​",
            "style": "IPY_MODEL_61de59b6cc194a52819df835686d221c",
            "value": " 674/674 [00:00&lt;00:00, 55.3kB/s]"
          }
        },
        "0bbbdb322682490db94225044037ab39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9c6228306c4a58a66028142700f910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19d5560e2bc24e2c94d0d47fae127a99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dde30297fd2405e8c1eb8ccabd5593c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e52c3e5a2854e9294223c648db4c368": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3891329fb6e344d598e41f9a62f038c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb5da5a71b34b28835bdc67d1920eef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61de59b6cc194a52819df835686d221c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7856c2e6e0174b5180121f77d2fbd5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79d7a6504eef4129917bca32900c2d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19d5560e2bc24e2c94d0d47fae127a99",
            "placeholder": "​",
            "style": "IPY_MODEL_7a7b4d057a3141359260d6b1a513c8d9",
            "value": "vocab.txt: 100%"
          }
        },
        "7a7b4d057a3141359260d6b1a513c8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "904a021bb4a34fc5b447fcf3caedcbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d246d03c7c2c48199730ce5e2057ad45",
              "IPY_MODEL_00b186e3bca14b378c2846988198c4c8",
              "IPY_MODEL_06481826277a4e63b7e21163e8049920"
            ],
            "layout": "IPY_MODEL_ff5b740324814178857be9538e7a0ed1"
          }
        },
        "bb76e8dd8e624b2aa3301bb5251fc895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e52c3e5a2854e9294223c648db4c368",
            "placeholder": "​",
            "style": "IPY_MODEL_7856c2e6e0174b5180121f77d2fbd5c4",
            "value": " 267k/267k [00:00&lt;00:00, 5.87MB/s]"
          }
        },
        "c3304afb280d4d48800d800768c0213e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9de7a2f9aa944c6a53d0d86fd680d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d246d03c7c2c48199730ce5e2057ad45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3891329fb6e344d598e41f9a62f038c9",
            "placeholder": "​",
            "style": "IPY_MODEL_c3304afb280d4d48800d800768c0213e",
            "value": "config.json: 100%"
          }
        },
        "e4c49088048345d69287a2406b3c25be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79d7a6504eef4129917bca32900c2d6d",
              "IPY_MODEL_f69d9f6815704a73b0b3f737a31b8efa",
              "IPY_MODEL_bb76e8dd8e624b2aa3301bb5251fc895"
            ],
            "layout": "IPY_MODEL_5bb5da5a71b34b28835bdc67d1920eef"
          }
        },
        "f69d9f6815704a73b0b3f737a31b8efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bbbdb322682490db94225044037ab39",
            "max": 266699,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d9c6228306c4a58a66028142700f910",
            "value": 266699
          }
        },
        "fb6b8a2b56df4c38b1e41d75b7c984c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff5b740324814178857be9538e7a0ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
